{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lucywowen/csci591_CCN/blob/main/assignments/assignment_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INkAgt-hTY_-"
      },
      "source": [
        "# Assignment 2 -  Modeling data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTEAadCkTZAA"
      },
      "source": [
        "## *YOUR FULL NAME HERE*\n",
        "Netid: Your netid here\n",
        "\n",
        "*Names of students you worked with on this assignment*: LIST HERE IF APPLICABLE (delete if not)\n",
        "\n",
        "Note: this assignment falls under collaboration Mode 2: Individual Assignment – Collaboration Permitted. Please refer to the syllabus on Canvas for additional information."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzkmvTNfTZAA"
      },
      "source": [
        "Instructions for all assignments can be found [here](https://github.com/lucywowen/csci547_ML/blob/main/assignments/_Assignment%20Instructions.ipynb) and in the course syllabus on canvas.\n",
        "\n",
        "Total points in the assignment add up to 90; an additional 10 points are allocated to presentation quality."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAPvzGDXTZAA"
      },
      "source": [
        "#  Learning Objectives\n",
        "The purpose of this assignment is to provide a deeper understanding into some of the recent concepts we've covered.  We'll work through a logistic regression analysis as well as apply some clustering technqiues using real brain data.  We'll also get those group projects started.  Please allow for enough time for this last section.  This will set you up for your group project analyses and hopefully get those wheels in motion!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntZoXcmBTZAB"
      },
      "source": [
        "*Note: for all assignments, write out all equations and math using markdown and [LaTeX](https://tobi.oetiker.ch/lshort/lshort.pdf). For this assignment show ALL math work*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kS629PqTZAD"
      },
      "source": [
        "**ANSWER**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJo_2az4TZAD"
      },
      "source": [
        "# Logistic regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeMy78fGTZAD"
      },
      "source": [
        "## 1\n",
        "**[30 points]**\n",
        "\n",
        "\n",
        "**Data**. The data for this problem can be found in the `data` subfolder in the `assignments` folder on [github](https://github.com/lucywowen/csci591_CCN). The filename is `stroke.csv`.\n",
        "\n",
        "A stroke occurs when the blood flow to a part of the brain is reduced or restricted. Due to this brain cells start to die, in that part of the brain, at a very fast rate due to a lack of oxygen and nutrients. There are two types of brain strokes: (a) Ischemic stroke and (b) Haemorrhagic stroke of which ischemic stroke is more likely to occur. The rupture or blockage prevents blood and oxygen from reaching the brain’s tissues.\n",
        " Here we have used 8 input parameters like gender, age, various diseases, and smoking status in this dataset on brain stroke detection from Kaggle.\n",
        " The following information is provided about the patient:\n",
        "\n",
        "    \n",
        "|field    |description|\n",
        "|:-----   |:-----|\n",
        "|id       |unique identifier|\n",
        "|gender   |'Male', 'Female', or 'Other'|\n",
        "|age   |age of patient|\n",
        "|hypertension    |0 if patient doesn't have hypertension; 1 if patient has hypertension|\n",
        "|heart_disease      |0 if patient doesn't have heart disease; 1 if patient has heart disease|\n",
        "|ever_married     |'No', 'Yes'|\n",
        "|work_type |'children', 'Govt_jov', 'Never_worked', 'Private', 'Self-employed' |\n",
        "|Residence_type   |'Rural', 'Urban' |\n",
        "|avg_glucose_level |average glucose level of the patient|\n",
        "|bmi |body mass index of the patient|\n",
        "|smoking_status |'formerly smoked', 'never smoked', 'smokes', 'Unknown'|\n",
        "|stroke |0 if patient has not had a stroke; 1 if patient has had a stroke|\n",
        "\n",
        "\n",
        "**Your objective**. For this dataset, your goal is to create a logistic regression model that predicts which patients will more likely have a stroke.  Let's break it down:\n",
        "\n",
        "a. First load in the data. You've already explored this data a bit in the previous assignment, but it would be good to get know the data again.  Start by exploring some distributions of stroke occurrences based on categorical and numerical features using histograms.  \n",
        "\n",
        "b. What do you see about the distribution of the number of patients who have had a stroke compared to the number of patients who have not had a stroke?  Is this a balanced dataset?\n",
        "\n",
        "c. Data transformations: Since the dataset is a mixture of numeric and categorical data, use one-hot encoding to transform the categorical data. Then make sure to rescale your numerical data and either drop or impute missing values.\n",
        "\n",
        "d. Calculate correlations and plot some heatmaps to see how these variables relate to one another.\n",
        "\n",
        "e. Use `Scikit-Learn` to perform logistic regression and show your results using `classification_report`.  Interpret these results.  What's the overall accuracy?  But what is the precision and recall values for stroke and no stroke?  What does this mean in terms of the imbalanced data?\n",
        "\n",
        "f. Extra credit (5 points): Try to resample the data to address the imbalance and re-run logistic regression.  How does this change your interpretation of the classification results?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFX1SSqATZAD"
      },
      "source": [
        "**ANSWER**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ip7LwEpCTZAE"
      },
      "source": [
        "# PCA and KMeans\n",
        "## 2\n",
        "**[25 points]**\n",
        "\n",
        "**Data**. The data for this problem can be found in the `data` subfolder in the `assignments` folder on [github](https://github.com/lucywowen/csci591_CCN). The filename is `wave_form.csv`.\n",
        "\n",
        "Epilepsy is a form of brain disorder in which an excess of synchronous electrical brain activity leads to seizures which can range from having no outward symptom at all to jerking movements (tonic-clonic seizure) and loss of awareness (absence seizure). For some epilepsy patients surgical removal of the effected brain tissue can be an effective treatment. But before a surgery can be performed the diseased brain tissue needs to be precisely localized. To find this seizure focus, recording electrodes are inserted into the patients brain with which the neural activity can be monitored in real time. The electrophysiological data you'll be working with has been acquired from a human epilepsy patient and has already been processed to extract spike events.\n",
        "\n",
        "Spike events reflect the activity of individual neurons and therefore can give important insights into the nature of the disease. However, a single electrode will typically pick up signals from more than one neuron at a time. While this might not be an issue for locating the seizure focus, research questions related to the mechanisms behind epileptic seizures often require a more detailed understanding of which neuron was active at what time. So how can we figure out the how many neurons were contributing to our signal and when each of them was active?\n",
        "\n",
        "To do this we will use an unsupervised clustering algorithm (K-means clustering) to sort our spike data. However, the first thing we need to do is decide what features of our spike wave forms we want to feed into our algorithm.  To do this, we will apply principal component analysis (PCA) and use the principal components as features. While before each spike wave form was represented by 9 samples (in part a) the dimensionality is now reduced to only three features which allow us to assign each spike to a cluster.\n",
        "\n",
        "All that's left is deciding how many clusters we expect to find.  From literature review, we expect not to find more than two or three separable clusters from a single electrode recording. However, we'll also run the K-means function several times on our data and increase the number of clusters with every run.  That way we can decide based on the 'Elbow method'. Ready? Let's go...\n",
        "\n",
        "\n",
        "**Your objective**. For this dataset, you'll perform an analysis to attribute spikes to neurons.  Let's break it down:\n",
        "\n",
        "a. Load in the data and plot the wave forms on one plot.  The data are arranged as #spikes (2401) by #samples (100).  To do this randomly sample 100 spikes and plot those wave forms on one plot.  I have some code below to help get started with this.\n",
        "\n",
        "b. Principal component analysis (PCA) is a dimensionality reduction method which requires normalized data.  Use `Scikit Learn` for both the normalization (`MinMaxScaler()`) and `PCA` (you can use `n_components=12`).\n",
        "\n",
        "c. Run `KMeans` from `Scikit Learn` on your reduced data several times using more and more clusters (`n_clusters=1` to `n_clusters=8`).  Plot the `.inertia_` values for each corresponding cluster.  Do you see an elbow?  Where do you think it is?\n",
        "\n",
        "d. Plot the wave forms for `n_clusters=3`.\n",
        "\n",
        "e. What do these wave forms look like?  Have you seen other plots with this shape before?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l56U-8r9TZAE"
      },
      "source": [
        "**ANSWER**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wave_form_pd = pd.read_csv('wave_form.csv')\n",
        "wave_form = wave_form_pd.to_numpy()\n",
        "np.random.seed(10)\n",
        "fig, ax = plt.subplots(figsize=(15, 5))\n",
        "\n",
        "for i in range(100):\n",
        "    spike = np.random.randint(0, wave_form.shape[0])\n",
        "    ax.plot(...) # Plot that spike (you fill this in!)\n",
        "\n",
        "ax.set_xlim([0, 90])\n",
        "ax.set_xlabel('# sample', fontsize=20)\n",
        "ax.set_ylabel('amplitude [uV]', fontsize=20)\n",
        "ax.set_title('spike waveforms', fontsize=23)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JQgvMfaIE3fo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uENxx9_VTZAD"
      },
      "source": [
        "# Project data analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shzvGVzgTZAE"
      },
      "source": [
        "## 3\n",
        "**[35 points]**\n",
        "\n",
        "**Data**. The data you'll use for this section will be related to your project (either the data you're working on with your group or a different dataset related to your question).  \n",
        "\n",
        "**Objective**. For this you'll use a machine learning model (supervised or unsupervised... preferablly one we've discussed in class) to analyze your data. You can work with your group on this, but you should each submit a *different* analysis.  Here's some expectations:\n",
        "\n",
        "a. Exploration and visualization: Do some data exploration with at least 3 plots.\n",
        "\n",
        "b. Preprocessing: Perform any necessary data transformations and handle any missing data. Explain what you did!\n",
        "\n",
        "c. Modeling: Pick a model and analyze your data.  Explain your motivation behind this particular model.  Do forget to split your data into training and testing sets!\n",
        "\n",
        "d. Evaluation: Evaluate your model.  The metrics you use should be consistent with the model you chose.  Explain your results.\n",
        "\n",
        "e. Insights: Provide any insights this modeling exercise gave you and how will it inform your future work on this project?  Please write out your next steps for analyses.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BASw0yPhTZAE"
      },
      "source": [
        "**ANSWER**\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z-8f81sObiAS"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "nteract": {
      "version": "0.28.0"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "position": {
        "height": "643px",
        "left": "1548px",
        "right": "20px",
        "top": "121px",
        "width": "350px"
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": true
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}